# 框架一：轻量级适配模型 (LAM) 实验代码

## 1. 项目简介
该框架旨在深度探究在**低资源（小样本）**条件下，如何高效、高保真地向模型注入特定知识。系统性地比较了**全量微调 (Full Fine-tuning)** 与 **低秩适配 (LoRA)** 这两种主流微调范式，并分析**贪心解码与随机采样**对模型行为的影响。

## 2. 功能
- **模型实现**：使用 PyTorch 从零开始实现了一个标准的 Transformer 解码器架构 (`ToyLLM`)。
- **LoRA 实现**：实现了 `LoRALayer`，并将其无缝集成到多头注意力机制的查询（Q）和值（V）投影矩阵中，以实现参数高效微调。
- **策略对比**：在一个统一的流程中，完整对比了四种实验组合：
    1.  LoRA + 贪心解码
    2.  LoRA + 随机采样
    3.  全量微调 + 贪心解码
    4.  全量微调 + 随机采样
- **性能评估**：使用自然语言处理领域的标准评测指标——**BLEU** 和 **ROUGE-L**——来量化评估生成文本的质量。
- **结果可视化**：自动生成一系列高质量的对比图表，用于直观分析实验结果：
    -   训练损失收敛曲线图 (`convergence_curve.svg`)
    -   性能指标与参数量对比柱状图 (`bar_chart_comparison.svg`)
    -   综合性能雷达图 (`radar_chart_comparison.svg`)

## 3. 文件结构

```
/framework_one/
├── main.py                 
├── config.py               
├── model.py                
├── data_utils.py          
├── engine.py                       
└── plot_utils.py        
````

## 4. 环境配置

在运行此项目之前，请确保您已安装所有必需的 Python 库。

1.  **安装依赖**:

    ```txt
    torch
    matplotlib
    numpy
    tqdm
    nltk
    rouge_score
    ```

2.  **硬件要求**:
    代码会自动检测并使用可用的 GPU (CUDA)，如果未检测到 GPU，则会使用 CPU。为了获得较快的训练速度，建议在配备 NVIDIA GPU 的环境上运行。

## 5. 使用指南

#### **步骤 1: 准备数据**

将您的指令微调数据集准备成 JSON 格式。文件应包含一个 JSON 列表，其中每个对象都是一个字典，包含 `instruction`, `input`, 和 `output` 三个键。

示例 `lora_train.json`:
```json
[
    {
        "instruction": "一字拖是什么？",
        "input": "",
        "output": "一字拖是一种轻便的凉鞋，其特点是鞋面上只有一条或几条带子横跨脚背。"
    },
    {
        "instruction": "介绍一下人字拖。",
        "input": "",
        "output": "人字拖因其鞋带在脚趾间形成一个'人'字形而得名，是夏季非常受欢迎的休闲鞋履。"
    }
]
````

#### **步骤 2: 修改配置**

打开 `config.py` 文件，根据您的环境和需求修改以下参数：

  - `NUM_EPOCHS`: 训练的总轮数。
  - `LEARNING_RATE`: 学习率。
  - `file_path`: **必须**修改为您在步骤1中准备的数据文件的绝对路径。
  - `FIGURE_SAVE_PATH`: **必须**修改为您希望保存结果图表的目录路径。
  - `ModelConfig`: 您可以根据需要调整模型的架构参数，如 `d_model` (模型维度), `num_layers` (层数) 等。

#### **步骤 3: 运行实验**

完成配置后，在终端中直接运行主程序：

```bash
python main.py
```

#### **步骤 4: 查看结果**

程序运行结束后：

1.  **终端输出**:
      - 会显示 LoRA 和全量微调模型的可训练参数量。
      - 会展示训练过程的进度条和最终的训练损失。
      - 会打印四种组合在验证集上的 BLEU 和 ROUGE-L 平均分数。
      - 最后会打印不同模型对两个固定问题的具体回答，以供直观对比。
2.  **图表文件**:
      - 在您 `config.py` 中设置的 `FIGURE_SAVE_PATH` 目录下，会生成三个 `.svg` 格式的图表文件，详细展示了实验的各项对比结果。


